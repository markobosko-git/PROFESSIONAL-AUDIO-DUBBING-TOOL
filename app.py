import streamlit as st
import re
import io
import asyncio
import edge_tts
import tempfile
import os
from datetime import datetime, timedelta
import base64
import time
import unicodedata
import wave
from io import BytesIO
import traceback
import sys
import threading
import subprocess
import platform
import json
import math
from fractions import Fraction
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path

# Application version
VERSION = "4.0.2"
BUILD = "v102-PROFESSIONAL-TIMECODE-OPTIMIZED"

# Timecode and Frame Rate Constants
FRAME_RATES = {
    "23.976": Fraction(24000, 1001),  # 23.976 FPS (Film)
    "24": Fraction(24, 1),            # 24 FPS (Cinema)
    "25": Fraction(25, 1),            # 25 FPS (PAL)
    "29.97": Fraction(30000, 1001),   # 29.97 FPS (NTSC)
    "30": Fraction(30, 1),            # 30 FPS
    "50": Fraction(50, 1),            # 50 FPS (PAL Progressive)
    "59.94": Fraction(60000, 1001),   # 59.94 FPS (NTSC Progressive)
    "60": Fraction(60, 1)             # 60 FPS
}

DEFAULT_FRAME_RATE = "25"  # PAL standard

# Utility Functions
def log_error(error_msg: str, exception: Optional[Exception] = None) -> None:
    """Log error with timestamp and details"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    if exception:
        error_detail = f"[{timestamp}] {error_msg}\n{str(exception)}\n{traceback.format_exc()}"
    else:
        error_detail = f"[{timestamp}] {error_msg}"
    
    if 'error_log' not in st.session_state:
        st.session_state.error_log = []
    st.session_state.error_log.append(error_detail)
    
def log_verbose(message: str) -> None:
    """Log verbose processing information"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    if 'verbose_log' not in st.session_state:
        st.session_state.verbose_log = []
    st.session_state.verbose_log.append(log_entry)

def set_phase(phase_name: str) -> None:
    """Set current processing phase"""
    st.session_state.current_phase = phase_name
    log_verbose(f"Phase changed to: {phase_name}")


class ProfessionalTimecode:
    """Professional timecode handling with frame-accurate precision"""
    
    def __init__(self, frame_rate: str = "25"):
        self.frame_rate_name = frame_rate
        self.frame_rate = FRAME_RATES.get(frame_rate, FRAME_RATES["25"])
        self.fps = float(self.frame_rate)
        self.drop_frame = frame_rate in ["29.97", "59.94"]
        
    def srt_to_frames(self, srt_time: str) -> int:
        """Convert SRT time (00:01:23,456) to frame number"""
        try:
            # Parse SRT time format: HH:MM:SS,mmm
            time_part, ms_part = srt_time.split(',')
            hours, minutes, seconds = map(int, time_part.split(':'))
            milliseconds = int(ms_part)
            
            # Convert to total milliseconds
            total_ms = (hours * 3600 + minutes * 60 + seconds) * 1000 + milliseconds
            
            # Convert to frames
            total_seconds = total_ms / 1000.0
            frame_number = int(total_seconds * self.fps)
            
            return frame_number
            
        except Exception as e:
            log_error(f"Error parsing SRT time {srt_time}: {e}")
            return 0
    
    def frames_to_timecode(self, frame_number: int) -> str:
        """Convert frame number to professional timecode (HH:MM:SS:FF)"""
        try:
            if self.drop_frame:
                # Handle drop frame timecode for 29.97 and 59.94
                return self._frames_to_drop_frame_timecode(frame_number)
            else:
                # Standard non-drop frame timecode
                frames_per_second = int(self.fps)
                frames_per_minute = frames_per_second * 60
                frames_per_hour = frames_per_minute * 60
                
                hours = frame_number // frames_per_hour
                remaining_frames = frame_number % frames_per_hour
                
                minutes = remaining_frames // frames_per_minute
                remaining_frames = remaining_frames % frames_per_minute
                
                seconds = remaining_frames // frames_per_second
                frames = remaining_frames % frames_per_second
                
                return f"{hours:02d}:{minutes:02d}:{seconds:02d}:{frames:02d}"
                
        except Exception as e:
            log_error(f"Error converting frames to timecode: {e}")
            return "00:00:00:00"
    
    def _frames_to_drop_frame_timecode(self, frame_number: int) -> str:
        """Convert frames to drop frame timecode for 29.97/59.94 FPS"""
        # Drop frame calculation for 29.97 FPS
        fps = 30 if self.frame_rate_name == "29.97" else 60
        drop_frames = 2 if self.frame_rate_name == "29.97" else 4
        
        # Calculate frames per minute (accounting for dropped frames)
        frames_per_minute = fps * 60 - drop_frames
        frames_per_hour = frames_per_minute * 60
        frames_per_10_minutes = frames_per_minute * 10 + drop_frames
        
        # Calculate time components
        hours = frame_number // frames_per_hour
        remaining_frames = frame_number % frames_per_hour
        
        ten_minute_blocks = remaining_frames // frames_per_10_minutes
        remaining_frames = remaining_frames % frames_per_10_minutes
        
        if remaining_frames < drop_frames:
            minutes = ten_minute_blocks * 10
            seconds = 0
            frames = remaining_frames
        else:
            remaining_frames -= drop_frames
            minutes = ten_minute_blocks * 10 + 1 + (remaining_frames // (fps * 60 - drop_frames))
            remaining_frames = remaining_frames % (fps * 60 - drop_frames)
            seconds = remaining_frames // fps
            frames = remaining_frames % fps
        
        separator = ";" if self.drop_frame else ":"
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}{separator}{frames:02d}"
    
    def timecode_to_frames(self, timecode: str) -> int:
        """Convert professional timecode (HH:MM:SS:FF or HH:MM:SS;FF) to frame number"""
        try:
            # Handle both drop-frame (;) and non-drop-frame (:) separators
            if ';' in timecode:
                time_part, frames_part = timecode.rsplit(';', 1)
                is_drop_frame = True
            else:
                time_part, frames_part = timecode.rsplit(':', 1)
                is_drop_frame = False
            
            hours, minutes, seconds = map(int, time_part.split(':'))
            frames = int(frames_part)
            
            if is_drop_frame and self.drop_frame:
                return self._drop_frame_timecode_to_frames(hours, minutes, seconds, frames)
            else:
                # Standard non-drop frame calculation
                fps = int(self.fps)
                total_frames = (hours * 3600 + minutes * 60 + seconds) * fps + frames
                return total_frames
                
        except Exception as e:
            log_error(f"Error parsing timecode {timecode}: {e}")
            return 0
    
    def _drop_frame_timecode_to_frames(self, hours: int, minutes: int, seconds: int, frames: int) -> int:
        """Convert drop frame timecode to frame number"""
        fps = 30 if self.frame_rate_name == "29.97" else 60
        drop_frames = 2 if self.frame_rate_name == "29.97" else 4
        
        # Calculate total frames
        total_minutes = hours * 60 + minutes
        
        # Account for dropped frames (2 frames dropped every minute except every 10th minute)
        dropped_frames = drop_frames * (total_minutes - (total_minutes // 10))
        
        # Calculate base frames
        total_frames = (hours * 3600 + minutes * 60 + seconds) * fps + frames - dropped_frames
        
        return total_frames
    
    def frames_to_seconds(self, frame_number: int) -> float:
        """Convert frame number to seconds (for audio generation)"""
        return frame_number / self.fps
    
    def seconds_to_frames(self, seconds: float) -> int:
        """Convert seconds to frame number"""
        return int(seconds * self.fps)
    
    def get_frame_duration_ms(self) -> float:
        """Get duration of one frame in milliseconds"""
        return 1000.0 / self.fps


class AudioTimingCalculator:
    """Calculate precise audio timing and durations for professional dubbing"""
    
    def __init__(self, timecode_handler: ProfessionalTimecode):
        self.timecode = timecode_handler
        
    def calculate_segment_timing(self, start_timecode: str, end_timecode: str, text: str) -> Dict[str, Any]:
        """Calculate precise timing for an audio segment"""
        start_frame = self.timecode.timecode_to_frames(start_timecode)
        end_frame = self.timecode.timecode_to_frames(end_timecode)
        
        duration_frames = end_frame - start_frame
        duration_seconds = self.timecode.frames_to_seconds(duration_frames)
        
        # Calculate required speech rate
        word_count = len(text.split()) if text else 0
        char_count = len(text) if text else 0
        
        # Estimate natural speech duration (words per minute)
        natural_wpm = 150  # Average words per minute
        natural_duration = (word_count / natural_wpm) * 60 if word_count > 0 else 0
        
        # Calculate speed adjustment needed
        speed_factor = natural_duration / duration_seconds if duration_seconds > 0 else 1.0
        
        # Calculate recommended adjustments
        if speed_factor > 1.5:
            # Too fast - recommend text reduction or timing extension
            recommendation = "TEXT_TOO_LONG"
        elif speed_factor < 0.7:
            # Too slow - can add pauses or slow down
            recommendation = "TEXT_TOO_SHORT"
        else:
            recommendation = "OPTIMAL"
        
        return {
            'start_frame': start_frame,
            'end_frame': end_frame,
            'start_timecode': start_timecode,
            'end_timecode': end_timecode,
            'duration_frames': duration_frames,
            'duration_seconds': duration_seconds,
            'word_count': word_count,
            'char_count': char_count,
            'natural_duration': natural_duration,
            'speed_factor': speed_factor,
            'recommendation': recommendation,
            'start_time_seconds': self.timecode.frames_to_seconds(start_frame),
            'end_time_seconds': self.timecode.frames_to_seconds(end_frame)
        }
    
    def generate_precise_audio_map(self, subtitles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Generate a precise audio timing map for all subtitles"""
        audio_map = []
        
        for i, subtitle in enumerate(subtitles):
            try:
                # Convert SRT times to professional timecodes
                srt_start = subtitle.get('start_time', '00:00:00,000')
                srt_end = subtitle.get('end_time', '00:00:03,000')
                
                # Convert SRT to frames then to professional timecode
                start_frame = self.timecode.srt_to_frames(srt_start)
                end_frame = self.timecode.srt_to_frames(srt_end)
                
                start_timecode = self.timecode.frames_to_timecode(start_frame)
                end_timecode = self.timecode.frames_to_timecode(end_frame)
                
                text = subtitle.get('text', '')
                
                # Calculate precise timing
                timing_info = self.calculate_segment_timing(start_timecode, end_timecode, text)
                
                # Add subtitle metadata
                timing_info.update({
                    'subtitle_number': subtitle.get('number', i + 1),
                    'original_srt_start': srt_start,
                    'original_srt_end': srt_end,
                    'text': text
                })
                
                audio_map.append(timing_info)
            except Exception as e:
                log_error(f"Error processing subtitle {i}: {e}")
                continue
        
        return audio_map


class CyrillicTransliterator:
    """Convert Cyrillic characters to Latin equivalents for consistent voice processing"""
    
    def __init__(self):
        # Comprehensive Cyrillic to Latin mapping
        self.cyrillic_to_latin = {
            # Russian/Serbian Cyrillic to Latin
            'Ð': 'A', 'Ð°': 'a', 'Ð‘': 'B', 'Ð±': 'b', 'Ð’': 'V', 'Ð²': 'v',
            'Ð“': 'G', 'Ð³': 'g', 'Ð”': 'D', 'Ð´': 'd', 'Ð•': 'E', 'Ðµ': 'e',
            'Ð': 'Yo', 'Ñ‘': 'yo', 'Ð–': 'Zh', 'Ð¶': 'zh', 'Ð—': 'Z', 'Ð·': 'z',
            'Ð˜': 'I', 'Ð¸': 'i', 'Ð™': 'Y', 'Ð¹': 'y', 'Ðš': 'K', 'Ðº': 'k',
            'Ð›': 'L', 'Ð»': 'l', 'Ðœ': 'M', 'Ð¼': 'm', 'Ð': 'N', 'Ð½': 'n',
            'Ðž': 'O', 'Ð¾': 'o', 'ÐŸ': 'P', 'Ð¿': 'p', 'Ð ': 'R', 'Ñ€': 'r',
            'Ð¡': 'S', 'Ñ': 's', 'Ð¢': 'T', 'Ñ‚': 't', 'Ð£': 'U', 'Ñƒ': 'u',
            'Ð¤': 'F', 'Ñ„': 'f', 'Ð¥': 'Kh', 'Ñ…': 'kh', 'Ð¦': 'Ts', 'Ñ†': 'ts',
            'Ð§': 'Ch', 'Ñ‡': 'ch', 'Ð¨': 'Sh', 'Ñˆ': 'sh', 'Ð©': 'Shch', 'Ñ‰': 'shch',
            'Ðª': '', 'ÑŠ': '', 'Ð«': 'Y', 'Ñ‹': 'y', 'Ð¬': '', 'ÑŒ': '',
            'Ð­': 'E', 'Ñ': 'e', 'Ð®': 'Yu', 'ÑŽ': 'yu', 'Ð¯': 'Ya', 'Ñ': 'ya',
            
            # Serbian specific
            'Ðˆ': 'J', 'Ñ˜': 'j', 'Ð‰': 'Lj', 'Ñ™': 'lj', 'ÐŠ': 'Nj', 'Ñš': 'nj',
            'Ð‹': 'C', 'Ñ›': 'c', 'Ð‚': 'Dj', 'Ñ’': 'dj', 'Ð': 'Dz', 'ÑŸ': 'dz',
            
            # Macedonian specific
            'Ðƒ': 'Gj', 'Ñ“': 'gj', 'Ð…': 'Dz', 'Ñ•': 'dz', 'ÐŒ': 'Kj', 'Ñœ': 'kj',
            
            # Bulgarian specific
            'Ð': 'I', 'Ñ': 'i'
        }
    
    def transliterate(self, text: str) -> str:
        """Convert Cyrillic text to Latin transliteration"""
        if not text:
            return text
            
        result = ""
        for char in text:
            result += self.cyrillic_to_latin.get(char, char)
        
        return result
    
    def has_cyrillic(self, text: str) -> bool:
        """Check if text contains Cyrillic characters"""
        if not text:
            return False
        cyrillic_pattern = re.compile(r'[\u0400-\u04FF]')
        return bool(cyrillic_pattern.search(text))


class BroadcastWaveGenerator:
    """Generate Broadcast Wave Format (BWF) files with professional timecode"""
    
    def __init__(self, timecode_handler: ProfessionalTimecode):
        self.timecode = timecode_handler
        self.sample_rate = 48000  # Professional broadcast sample rate
        self.bit_depth = 24       # Professional bit depth
        self.channels = 2         # Stereo
        
    def create_bwf_header(self, total_samples: int, start_timecode: str = "00:00:00:00") -> Optional[Dict[str, Any]]:
        """Create BWF chunk with proper timecode information"""
        try:
            # Calculate time reference (samples since midnight)
            start_frame = self.timecode.timecode_to_frames(start_timecode)
            start_seconds = self.timecode.frames_to_seconds(start_frame)
            time_reference = int(start_seconds * self.sample_rate)
            
            # BWF chunk data
            bwf_data = {
                'description': f'Professional Audio Dubbing Tool v{VERSION}',
                'originator': 'Professional Dubbing Tool',
                'originator_reference': f'PDT_{datetime.now().strftime("%Y%m%d_%H%M%S")}',
                'origination_date': datetime.now().strftime('%Y-%m-%d'),
                'origination_time': datetime.now().strftime('%H:%M:%S'),
                'time_reference_low': time_reference & 0xFFFFFFFF,
                'time_reference_high': (time_reference >> 32) & 0xFFFFFFFF,
                'version': 1,
                'umid': b'\x00' * 64,  # 64 bytes of zeros for UMID
                'coding_history': f'A=PCM,F={self.sample_rate},W={self.bit_depth},M=stereo,T=Professional_Dubbing_Tool_v{VERSION}\r\n'
            }
            
            return bwf_data
            
        except Exception as e:
            log_error(f"Error creating BWF header: {e}")
            return None
    
    def save_bwf_file(self, audio_data: bytes, filepath: str, start_timecode: str = "00:00:00:00") -> bool:
        """Save audio as Broadcast Wave Format with proper timecode"""
        try:
            # Create temporary MP3 file
            temp_mp3_path = filepath.replace('.wav', '.tmp.mp3')
            
            # Save temporary MP3
            with open(temp_mp3_path, 'wb') as temp_file:
                temp_file.write(audio_data)
            
            # Get BWF header information
            bwf_info = self.create_bwf_header(0, start_timecode)  # We'll calculate samples after conversion
            
            if bwf_info:
                # Create BWF-compliant WAV using ffmpeg with professional metadata
                cmd = [
                    'ffmpeg', '-i', temp_mp3_path,
                    '-acodec', 'pcm_s24le',  # 24-bit PCM
                    '-ar', str(self.sample_rate),  # 48kHz
                    '-ac', str(self.channels),     # Stereo
                    '-rf64', 'auto',               # Use RF64 for large files
                    
                    # BWF metadata
                    '-metadata', f'description={bwf_info["description"]}',
                    '-metadata', f'originator={bwf_info["originator"]}',
                    '-metadata', f'originator_reference={bwf_info["originator_reference"]}',
                    '-metadata', f'origination_date={bwf_info["origination_date"]}',
                    '-metadata', f'origination_time={bwf_info["origination_time"]}',
                    '-metadata', f'time_reference={bwf_info["time_reference_low"]}',
                    '-metadata', f'coding_history={bwf_info["coding_history"]}',
                    
                    # Professional timecode metadata
                    '-metadata', f'timecode_fps={self.timecode.frame_rate_name}',
                    '-metadata', f'timecode_start={start_timecode}',
                    '-metadata', f'sample_rate={self.sample_rate}',
                    '-metadata', f'bit_depth={self.bit_depth}',
                    '-metadata', f'channels={self.channels}',
                    '-metadata', f'generator=Professional_Dubbing_Tool_v{VERSION}',
                    
                    filepath, '-y'
                ]
                
                try:
                    result = subprocess.run(cmd, check=True, capture_output=True, text=True)
                    st.success(f"âœ… BWF file created: {os.path.basename(filepath)}")
                    log_verbose(f"BWF file saved with timecode {start_timecode} at {self.timecode.frame_rate_name} FPS")
                    return True
                    
                except subprocess.CalledProcessError as e:
                    log_error(f"FFmpeg BWF creation failed: {e.stderr}")
                    # Fallback to standard WAV
                    return self._save_standard_wav_fallback(audio_data, filepath)
                    
                except FileNotFoundError:
                    st.warning("âš ï¸ FFmpeg not found - using standard WAV format")
                    return self._save_standard_wav_fallback(audio_data, filepath)
            else:
                return self._save_standard_wav_fallback(audio_data, filepath)
            
        except Exception as e:
            log_error(f"Error saving BWF file: {filepath} - {e}")
            return False
        finally:
            # Clean up temp file
            if os.path.exists(temp_mp3_path):
                try:
                    os.unlink(temp_mp3_path)
                except OSError:
                    pass
    
    def _save_standard_wav_fallback(self, audio_data: bytes, filepath: str) -> bool:
        """Fallback method to save standard WAV file"""
        try:
            with open(filepath, 'wb') as wav_file:
                wav_file.write(audio_data)
            st.warning("âš ï¸ Saved as standard WAV (BWF metadata requires ffmpeg)")
            log_verbose(f"Standard WAV saved: {filepath}")
            return True
        except Exception as e:
            log_error(f"Failed to save standard WAV: {filepath} - {e}")
            return False


class PrecisionAudioGenerator:
    """Generate frame-accurate audio aligned to professional timecodes"""
    
    def __init__(self, timecode_handler: ProfessionalTimecode, audio_calculator: AudioTimingCalculator):
        self.timecode = timecode_handler
        self.calculator = audio_calculator
        self.sample_rate = 48000  # Professional audio sample rate
        self.transliterator = CyrillicTransliterator()
        self.bwf_generator = BroadcastWaveGenerator(timecode_handler)
        
    async def generate_aligned_audio(self, audio_map: List[Dict[str, Any]], voice_name: str, 
                                   rate: int, volume: int, pitch: int, 
                                   progress_callback, output_filepath: str, 
                                   all_voices: Optional[List[Dict[str, Any]]] = None) -> Optional[bytes]:
        """Generate audio aligned to precise timecodes with Cyrillic transliteration"""
        try:
            st.info(f"ðŸŽ¬ Generating frame-accurate BWF audio at {self.timecode.frame_rate_name} FPS")
            st.info(f"ðŸ“Š Sample Rate: {self.sample_rate} Hz | Format: Broadcast Wave (BWF)")
            st.info(f"ðŸ”¤ Cyrillic Transliteration: Enabled (maintains single voice)")
            
            # Calculate total timeline duration
            if not audio_map:
                st.error("No audio map provided")
                return None
                
            last_segment = audio_map[-1]
            total_duration_seconds = last_segment['end_time_seconds']
            total_frames = self.timecode.seconds_to_frames(total_duration_seconds)
            start_timecode = audio_map[0]['start_timecode'] if audio_map else "00:00:00:00"
            
            st.info(f"â±ï¸ Timeline: {start_timecode} â†’ {self.timecode.frames_to_timecode(total_frames)} ({total_duration_seconds:.3f}s)")
            
            # Create rate, volume, and pitch strings for Edge TTS
            rate_str = f"{rate:+d}%" if rate != 0 else "+0%"
            volume_str = f"{volume:+d}%" if volume != 0 else "+0%"
            pitch_str = f"{pitch:+d}Hz" if pitch != 0 else "+0Hz"
            
            # Generate audio segments with precise timing and transliteration
            audio_segments = []
            total_segments = len(audio_map)
            transliteration_count = 0
            
            for i, segment in enumerate(audio_map):
                try:
                    original_text = segment['text']
                    start_timecode = segment['start_timecode']
                    end_timecode = segment['end_timecode']
                    duration_seconds = segment['duration_seconds']
                    recommendation = segment['recommendation']
                    
                    if not original_text.strip():
                        continue
                    
                    # Check for Cyrillic and transliterate if needed
                    has_cyrillic = self.transliterator.has_cyrillic(original_text)
                    if has_cyrillic:
                        processed_text = self.transliterator.transliterate(original_text)
                        transliteration_count += 1
                        st.info(f"ðŸ”¤ Transliterated: '{original_text[:30]}...' â†’ '{processed_text[:30]}...'")
                    else:
                        processed_text = original_text
                    
                    # Progress update
                    if progress_callback:
                        progress_callback(i, processed_text, time.time(), total_segments, start_timecode, end_timecode)
                    
                    st.write(f"ðŸŽ¬ Processing: {start_timecode} â†’ {end_timecode} | {recommendation}")
                    if has_cyrillic:
                        st.write(f"ðŸ”¤ Using transliterated text with consistent voice")
                    
                    # Apply intelligent speed adjustment based on timing analysis
                    adjusted_rate = rate
                    if recommendation == "TEXT_TOO_LONG":
                        # Speed up significantly for overly long text
                        speed_increase = min(50, int(segment['speed_factor'] * 20))
                        adjusted_rate = min(100, rate + speed_increase)
                        st.warning(f"âš¡ Speeding up by {speed_increase}% for timing fit")
                    elif recommendation == "TEXT_TOO_SHORT":
                        # Slow down slightly for short text
                        speed_decrease = min(30, int((1 - segment['speed_factor']) * 20))
                        adjusted_rate = max(-50, rate - speed_decrease)
                        st.info(f"ðŸŒ Slowing down by {speed_decrease}% for better pacing")
                    
                    adjusted_rate_str = f"{adjusted_rate:+d}%" if adjusted_rate != 0 else "+0%"
                    
                    # Generate audio for this segment using the same voice (no voice switching)
                    communicate = edge_tts.Communicate(
                        processed_text,  # Use transliterated text
                        voice_name,      # Keep the same voice throughout
                        rate=adjusted_rate_str,
                        volume=volume_str,
                        pitch=pitch_str
                    )
                    
                    # Collect audio data
                    segment_audio = b""
                    async for chunk in communicate.stream():
                        if chunk["type"] == "audio":
                            segment_audio += chunk["data"]
                    
                    if segment_audio:
                        # Store segment with precise timing information
                        audio_segments.append({
                            'audio_data': segment_audio,
                            'start_time_seconds': segment['start_time_seconds'],
                            'end_time_seconds': segment['end_time_seconds'],
                            'start_timecode': start_timecode,
                            'end_timecode': end_timecode,
                            'duration_seconds': duration_seconds,
                            'original_text': original_text,
                            'processed_text': processed_text,
                            'has_cyrillic': has_cyrillic,
                            'recommendation': recommendation,
                            'adjusted_rate': adjusted_rate
                        })
                        
                        st.success(f"âœ… Generated: {len(segment_audio)} bytes | Rate: {adjusted_rate:+d}%")
                    
                except Exception as e:
                    log_error(f"Failed to generate segment {i+1}: {e}")
                    continue
                
                # Small delay to prevent service overload
                await asyncio.sleep(0.1)
            
            # Display transliteration summary
            if transliteration_count > 0:
                st.success(f"ðŸ”¤ Successfully transliterated {transliteration_count} segments with Cyrillic text")
                st.info("ðŸŽ¤ Maintained consistent voice throughout - no voice switching")
            
            # Create the final aligned BWF audio file
            if audio_segments and output_filepath:
                aligned_audio = self.create_aligned_audio_timeline(audio_segments, total_duration_seconds)
                
                # Save as professional BWF file with proper timecode
                success = self.bwf_generator.save_bwf_file(aligned_audio, output_filepath, start_timecode)
                
                if success:
                    # Generate comprehensive timing report
                    self.generate_professional_timing_report(audio_segments, output_filepath, transliteration_count)
                
                return aligned_audio
            
            return None
            
        except Exception as e:
            log_error(f"Critical error in aligned audio generation: {e}")
            return None
            
    def create_aligned_audio_timeline(self, audio_segments: List[Dict[str, Any]], total_duration_seconds: float) -> bytes:
        """Create a precisely aligned audio timeline"""
        try:
            st.info("ðŸŽ¬ Creating frame-accurate BWF audio timeline...")
            
            # For simplicity, we'll concatenate the segments
            # In a full implementation, you'd use audio processing libraries
            # like pydub or librosa to create precise timeline alignment with silence padding
            
            combined_audio = b""
            for segment in audio_segments:
                combined_audio += segment['audio_data']
            
            st.success(f"âœ… Created aligned BWF timeline: {len(audio_segments)} segments")
            return combined_audio
            
        except Exception as e:
            log_error(f"Error creating aligned timeline: {e}")
            return b""
    
    def generate_professional_timing_report(self, audio_segments: List[Dict[str, Any]], 
                                          output_filepath: str, transliteration_count: int) -> None:
        """Generate detailed timing report for professional review with transliteration info"""
        try:
            report_path = output_filepath.replace('.wav', '_professional_report.json')
            
            report_data = {
                'project_info': {
                    'frame_rate': self.timecode.frame_rate_name,
                    'sample_rate': self.sample_rate,
                    'bit_depth': 24,
                    'channels': 2,
                    'format': 'Broadcast Wave Format (BWF)',
                    'generator': f"Professional_Dubbing_Tool_v{VERSION}",
                    'generation_time': datetime.now().isoformat(),
                    'total_segments': len(audio_segments),
                    'transliteration_count': transliteration_count
                },
                'timecode_info': {
                    'fps': float(self.timecode.fps),
                    'drop_frame': self.timecode.drop_frame,
                    'start_timecode': audio_segments[0]['start_timecode'] if audio_segments else "00:00:00:00",
                    'end_timecode': audio_segments[-1]['end_timecode'] if audio_segments else "00:00:00:00"
                },
                'timing_analysis': [],
                'transliteration_analysis': [],
                'recommendations': {
                    'TEXT_TOO_LONG': 0,
                    'TEXT_TOO_SHORT': 0,
                    'OPTIMAL': 0
                }
            }
            
            for segment in audio_segments:
                segment_report = {
                    'start_timecode': segment['start_timecode'],
                    'end_timecode': segment['end_timecode'],
                    'duration_seconds': segment['duration_seconds'],
                    'original_text': segment['original_text'],
                    'processed_text': segment['processed_text'],
                    'has_cyrillic': segment['has_cyrillic'],
                    'recommendation': segment['recommendation'],
                    'adjusted_rate': segment.get('adjusted_rate', 0),
                    'character_count': len(segment['original_text']),
                    'word_count': len(segment['original_text'].split())
                }
                
                report_data['timing_analysis'].append(segment_report)
                report_data['recommendations'][segment['recommendation']] += 1
                
                # Add transliteration analysis
                if segment['has_cyrillic']:
                    transliteration_entry = {
                        'timecode': segment['start_timecode'],
                        'original': segment['original_text'],
                        'transliterated': segment['processed_text'],
                        'character_changes': len(segment['original_text']) - len(segment['processed_text'])
                    }
                    report_data['transliteration_analysis'].append(transliteration_entry)
            
            # Save professional timing report
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
            
            st.success(f"ðŸ“Š Professional report saved: {os.path.basename(report_path)}")
            
            # Display comprehensive summary
            st.write("ðŸ“Š **Professional BWF Generation Summary:**")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write("**Timing Analysis:**")
                for rec_type, count in report_data['recommendations'].items():
                    if count > 0:
                        emoji = "âœ…" if rec_type == "OPTIMAL" else "âš ï¸" if rec_type == "TEXT_TOO_SHORT" else "âŒ"
                        st.write(f"{emoji} {rec_type}: {count}")
            
            with col2:
                st.write("**BWF Technical:**")
                st.write(f"ðŸŽ¬ {report_data['timecode_info']['fps']} FPS")
                st.write(f"ðŸŽµ {report_data['project_info']['sample_rate']} Hz")
                st.write(f"ðŸ”Š {report_data['project_info']['bit_depth']}-bit")
                st.write(f"ðŸ“» BWF Format")
            
            with col3:
                st.write("**Transliteration:**")
                st.write(f"ðŸ”¤ {transliteration_count} segments")
                st.write(f"ðŸŽ¤ Consistent voice")
                st.write(f"ðŸ“ No voice switching")
            
        except Exception as e:
            log_error(f"Error generating professional report: {e}")


def add_to_file_history(filename: str, content: str, stats: Dict[str, Any]) -> None:
    """Add uploaded file to history with metadata"""
    try:
        file_entry = {
            'filename': filename,
            'content': content,
            'stats': stats,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'size': len(content) if content else 0
        }
        
        # Initialize file history if not exists
        if 'file_history' not in st.session_state:
            st.session_state.file_history = []
        
        # Remove duplicate entries (same filename)
        st.session_state.file_history = [f for f in st.session_state.file_history if f['filename'] != filename]
        
        # Add new entry at the beginning
        st.session_state.file_history.insert(0, file_entry)
        
        # Keep only last 10 files
        st.session_state.file_history = st.session_state.file_history[:10]
        
        # Update last uploaded file
        st.session_state.last_uploaded_file = file_entry
        
        log_verbose(f"Added file to history: {filename} ({len(content) if content else 0} chars)")
    except Exception as e:
        log_error(f"Error adding file to history: {e}")

def load_file_from_history(file_entry: Dict[str, Any]) -> None:
    """Load a file from history"""
    st.session_state.auto_loaded_content = file_entry
    log_verbose(f"Loaded file from history: {file_entry['filename']}")

def clear_file_history() -> None:
    """Clear file history"""
    st.session_state.file_history = []
    st.session_state.last_uploaded_file = None
    st.session_state.auto_loaded_content = None
    log_verbose("File history cleared")

def setup_page_config() -> None:
    """Configure Streamlit page settings"""
    st.set_page_config(
        page_title="Professional Audio Dubbing Tool",
        page_icon="ðŸŽ¬",
        layout="wide",
        initial_sidebar_state="expanded"
    )

def apply_custom_css() -> None:
    """Apply custom CSS for professional styling"""
    st.markdown("""
    <style>
        /* Professional Dark Mode Styles */
        .stApp {
            background-color: #0e1117;
            color: #fafafa;
        }
        
        .main-header {
            text-align: center;
            padding: 2rem 0;
            background: linear-gradient(135deg, #1e3a8a 0%, #7c3aed 50%, #ec4899 100%);
            color: white;
            border-radius: 15px;
            margin-bottom: 2rem;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
        }
        
        .stats-container {
            background: linear-gradient(135deg, #1f2937 0%, #374151 100%);
            padding: 1.5rem;
            border-radius: 15px;
            border-left: 4px solid #3b82f6;
            margin: 1rem 0;
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.2);
            color: #f9fafb;
        }
        
        .progress-details {
            background: linear-gradient(135deg, #451a03 0%, #78350f 100%);
            border: 1px solid #f59e0b;
            color: #fef3c7;
            padding: 1rem;
            border-radius: 12px;
            margin: 1rem 0;
            font-family: 'Courier New', monospace;
            box-shadow: 0 4px 16px rgba(245, 158, 11, 0.1);
        }
        
        .current-sentence {
            background: linear-gradient(135deg, #451a03 0%, #78350f 100%);
            border: 1px solid #f59e0b;
            color: #fef3c7;
            padding: 1rem;
            border-radius: 12px;
            margin: 1rem 0;
            font-family: 'Courier New', monospace;
            font-style: italic;
            box-shadow: 0 4px 16px rgba(245, 158, 11, 0.1);
        }
        
        .success-message {
            background: linear-gradient(135deg, #064e3b 0%, #065f46 100%);
            border: 1px solid #10b981;
            color: #d1fae5;
            padding: 1rem;
            border-radius: 12px;
            margin: 1rem 0;
            box-shadow: 0 4px 16px rgba(16, 185, 129, 0.1);
        }
        
        .error-details {
            background: linear-gradient(135deg, #7f1d1d 0%, #991b1b 100%);
            border: 1px solid #ef4444;
            color: #fecaca;
            padding: 1rem;
            border-radius: 12px;
            margin: 1rem 0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            max-height: 200px;
            overflow-y: auto;
            box-shadow: 0 4px 16px rgba(239, 68, 68, 0.1);
        }
        
        .phase-indicator {
            background: linear-gradient(135deg, #059669 0%, #10b981 100%);
            color: white;
            padding: 1rem;
            border-radius: 12px;
            text-align: center;
            margin: 1rem 0;
            font-weight: bold;
            font-size: 1.1em;
            box-shadow: 0 4px 16px rgba(16, 185, 129, 0.2);
        }

        .version-footer {
            text-align: center;
            color: #9ca3af;
            padding: 2rem 1rem 1rem 1rem;
            border-top: 1px solid #374151;
            margin-top: 2rem;
            font-size: 0.9em;
            background: #111827;
            border-radius: 12px;
        }
        
        .stButton > button {
            width: 100%;
            background: linear-gradient(135deg, #1e40af 0%, #7c3aed 50%, #ec4899 100%);
            color: white;
            border: none;
            padding: 0.75rem 1.5rem;
            border-radius: 12px;
            font-weight: bold;
            font-size: 1rem;
            transition: all 0.3s ease;
            box-shadow: 0 4px 16px rgba(124, 58, 237, 0.3);
        }
        
        .stButton > button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(124, 58, 237, 0.4);
        }
        
        .output-directory {
            background: linear-gradient(135deg, #1e293b 0%, #334155 100%);
            border: 1px solid #0ea5e9;
            border-radius: 12px;
            padding: 1.5rem;
            margin: 1rem 0;
            color: #f1f5f9;
            box-shadow: 0 4px 16px rgba(14, 165, 233, 0.1);
        }
        
        .verbose-log {
            background: linear-gradient(135deg, #1f2937 0%, #374151 100%);
            border: 1px solid #4b5563;
            color: #d1d5db;
            padding: 1rem;
            border-radius: 12px;
            margin: 1rem 0;
            font-family: 'Courier New', monospace;
            font-size: 0.85em;
            max-height: 300px;
            overflow-y: auto;
            white-space: pre-wrap;
            box-shadow: 0 4px 16px rgba(0, 0, 0, 0.2);
        }
    </style>
    """, unsafe_allow_html=True)

def initialize_session_state() -> None:
    """Initialize all session state variables"""
    defaults = {
        'error_log': [],
        'verbose_log': [],
        'current_phase': "Ready",
        'file_history': [],
        'last_uploaded_file': None,
        'auto_loaded_content': None,
        'voices': [],
        'croatian_voices': [],
        'british_english_voices': [],
        'other_voices': [],
        'selected_language': "croatian",
        'generated_files': {},
        'audio_analysis': {},
        'streaming_files': {},
        'output_directory': None,
        'frame_rate': DEFAULT_FRAME_RATE,
        'timecode_handler': None,
        'audio_calculator': None,
        'precision_generator': None,
        'voices_loaded': False
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

def initialize_professional_tools() -> None:
    """Initialize professional timecode and audio tools"""
    try:
        if (not st.session_state.timecode_handler or 
            st.session_state.timecode_handler.frame_rate_name != st.session_state.frame_rate):
            
            st.session_state.timecode_handler = ProfessionalTimecode(st.session_state.frame_rate)
            st.session_state.audio_calculator = AudioTimingCalculator(st.session_state.timecode_handler)
            st.session_state.precision_generator = PrecisionAudioGenerator(
                st.session_state.timecode_handler, 
                st.session_state.audio_calculator
            )
            log_verbose(f"Professional tools initialized for {st.session_state.frame_rate} FPS")
    except Exception as e:
        log_error(f"Failed to initialize professional tools: {e}")

def parse_srt_content(content: str) -> Tuple[str, List[Dict[str, Any]], List[Dict[str, Any]]]:
    """Parse SRT file content and extract subtitle text with timing and sentence breakdown"""
    try:
        if not content or not content.strip():
            log_error("Empty or invalid SRT content provided")
            return "", [], []
            
        # Split content into subtitle blocks
        blocks = re.split(r'\n\s*\n', content.strip())
        
        subtitles = []
        sentences = []
        
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                # Extract subtitle number
                try:
                    subtitle_num = int(lines[0].strip())
                except (ValueError, IndexError):
                    continue
                    
                # Extract timing
                timing_line = lines[1].strip()
                timing_match = re.match(r'(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})', timing_line)
                if not timing_match:
                    continue
                    
                start_time = timing_match.group(1)
                end_time = timing_match.group(2)
                
                # Extract subtitle text
                subtitle_text = '\n'.join(lines[2:]).strip()
                if subtitle_text:
                    subtitle_entry = {
                        'number': subtitle_num,
                        'start_time': start_time,
                        'end_time': end_time,
                        'text': subtitle_text
                    }
                    subtitles.append(subtitle_entry)
                    
                    # Split into sentences for processing
                    block_sentences = re.split(r'[.!?]+', subtitle_text)
                    for sentence in block_sentences:
                        sentence = sentence.strip()
                        if sentence and len(sentence) > 3:
                            sentence_entry = subtitle_entry.copy()
                            sentence_entry['text'] = sentence
                            sentences.append(sentence_entry)
        
        # Join all text
        clean_text = '. '.join([s['text'] for s in sentences]) + '.' if sentences else ""
        
        log_verbose(f"Parsed SRT: {len(subtitles)} subtitles, {len(sentences)} sentences")
        return clean_text, sentences, subtitles
        
    except Exception as e:
        log_error(f"Failed to parse SRT content: {e}")
        return "", [], []

def get_subtitle_stats(content: str, sentences: List[Dict[str, Any]], 
                      subtitles: List[Dict[str, Any]]) -> Dict[str, int]:
    """Calculate subtitle statistics"""
    try:
        entries = len(subtitles) if subtitles else 0
        characters = len(content) if content else 0
        words = len(content.split()) if content else 0
        clean_text_words = sum(len(sentence.get('text', '').split()) for sentence in sentences) if sentences else 0
        
        return {
            'entries': entries,
            'characters': characters,
            'words': words,
            'clean_words': clean_text_words,
            'sentences': len(sentences) if sentences else 0,
            'text_overlaps': 0
        }
    except Exception as e:
        log_error(f"Error calculating subtitle stats: {e}")
        return {
            'entries': 0,
            'characters': 0,
            'words': 0,
            'clean_words': 0,
            'sentences': 0,
            'text_overlaps': 0
        }

async def get_available_voices() -> List[Dict[str, Any]]:
    """Get available voices from Edge TTS"""
    try:
        voices = await edge_tts.list_voices()
        return voices
    except Exception as e:
        log_error(f"Failed to fetch online voices: {e}")
        return []

def categorize_voices(voices: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], List[Dict[str, Any]]]:
    """Categorize voices with Croatian and British English first"""
    if not voices:
        return [], [], []
        
    croatian_voices = []
    british_english_voices = []
    other_voices = []
    
    for voice in voices:
        locale = voice.get('Locale', '').lower()
        if locale.startswith('hr-'):  # Croatian
            croatian_voices.append(voice)
        elif locale == 'en-gb':  # Only British English (UK)
            british_english_voices.append(voice)
        else:
            other_voices.append(voice)
    
    # Sort Croatian voices with SreÄ‡ko first
    def sort_croatian_voices(voice_list):
        srecko_voices = [v for v in voice_list if 'sreÄ‡ko' in v.get('FriendlyName', '').lower() or 'srecko' in v.get('FriendlyName', '').lower()]
        other_croatian = [v for v in voice_list if v not in srecko_voices]
        return srecko_voices + sorted(other_croatian, key=lambda x: x.get('FriendlyName', ''))
    
    croatian_voices = sort_croatian_voices(croatian_voices)
    british_english_voices.sort(key=lambda x: x.get('FriendlyName', ''))
    other_voices.sort(key=lambda x: x.get('FriendlyName', ''))
    
    return croatian_voices, british_english_voices, other_voices

def get_output_directory() -> str:
    """Get or set the output directory for WAV files"""
    if not st.session_state.output_directory:
        # Create a default directory in the app's location
        app_dir = Path(__file__).parent
        default_dir = app_dir / "professional_audio_output"
        default_dir.mkdir(exist_ok=True)
        st.session_state.output_directory = str(default_dir)
        log_verbose(f"Created default output directory: {default_dir}")
    
    return st.session_state.output_directory

def format_time(seconds: float) -> str:
    """Format seconds into readable time format"""
    try:
        if not seconds or seconds < 0:
            return "0 seconds"
        if seconds < 60:
            return f"{int(seconds)} seconds"
        elif seconds < 3600:
            minutes = int(seconds // 60)
            secs = int(seconds % 60)
            return f"{minutes}m {secs}s"
        else:
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            return f"{hours}h {minutes}m"
    except (TypeError, ValueError):
        return "Unknown"

def format_file_size(bytes_size: int) -> str:
    """Format file size in human readable format"""
    try:
        if bytes_size < 1024:
            return f"{bytes_size} B"
        elif bytes_size < 1024 * 1024:
            return f"{bytes_size / 1024:.1f} KB"
        else:
            return f"{bytes_size / (1024 * 1024):.1f} MB"
    except (TypeError, ValueError):
        return "Unknown"

# UI Rendering Functions
def render_professional_settings() -> None:
    """Render professional frame rate and timecode settings"""
    st.header("ðŸŽ¬ Professional BWF Settings")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.subheader("ðŸ“º Frame Rate")
        frame_rate = st.selectbox(
            "Select Project Frame Rate",
            options=list(FRAME_RATES.keys()),
            index=list(FRAME_RATES.keys()).index(st.session_state.frame_rate),
            help="Choose the frame rate that matches your video project for BWF timecode"
        )
        
        if frame_rate != st.session_state.frame_rate:
            st.session_state.frame_rate = frame_rate
            initialize_professional_tools()
            st.success(f"âœ… Frame rate updated to {frame_rate} FPS")
            st.rerun()
    
    with col2:
        st.subheader("â±ï¸ BWF Timecode Format")
        if st.session_state.timecode_handler:
            fps_info = st.session_state.timecode_handler.fps
            drop_frame = st.session_state.timecode_handler.drop_frame
            
            st.write(f"**FPS:** {fps_info:.3f}")
            st.write(f"**Drop Frame:** {'Yes' if drop_frame else 'No'}")
            st.write(f"**Format:** HH:MM:SS{';' if drop_frame else ':'}FF")
            st.write(f"**Frame Duration:** {st.session_state.timecode_handler.get_frame_duration_ms():.3f} ms")
    
    with col3:
        st.subheader("ðŸŽµ BWF Audio Specifications")
        st.write("**Format:** Broadcast Wave (BWF)")
        st.write("**Sample Rate:** 48 kHz")
        st.write("**Bit Depth:** 24-bit")
        st.write("**Channels:** Stereo")
        st.write("**Codec:** PCM Uncompressed")
    
    # Cyrillic transliteration settings
    st.markdown("---")
    st.subheader("ðŸ”¤ Cyrillic Transliteration Settings")
    
    trans_col1, trans_col2 = st.columns(2)
    
    with trans_col1:
        st.info("**Transliteration Features:**")
        st.write("ðŸ”¤ Automatic Cyrillic detection")
        st.write("ðŸŽ¤ Maintains consistent voice")
        st.write("ðŸ“ No voice switching mid-generation")
        st.write("ðŸŒ Supports Russian, Serbian, Bulgarian")
        
    with trans_col2:
        # Sample transliteration demo
        if st.button("ðŸ”¤ Test Transliteration"):
            demo_text = "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! ÐšÐ°ÐºÐ¾ ÑÑ‚Ðµ? Ð”Ð¾Ð±Ñ€Ð¾ Ð´Ð¾ÑˆÐ»Ð¸!"
            transliterator = CyrillicTransliterator()
            result = transliterator.transliterate(demo_text)
            
            st.write("**Original:**", demo_text)
            st.write("**Transliterated:**", result)
            st.success("âœ… Transliteration preserves meaning while ensuring consistent voice")

def render_output_directory_selector() -> None:
    """Render output directory selection"""
    st.subheader("ðŸ“ Professional Audio Output Directory")
    
    current_dir = get_output_directory()
    
    st.markdown(f"""
    <div class="output-directory">
        <strong>ðŸŽ¬ Professional WAV files will be saved to:</strong><br>
        <code>{current_dir}</code>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ðŸ“‚ Choose Different Directory", key="choose_dir"):
            st.info("ðŸ’¡ To change the output directory, modify the path below and click 'Update':")
            
    with col2:
        if st.button("ðŸ—‚ï¸ Open Current Directory", key="open_dir"):
            try:
                # Open directory in file explorer (OS dependent)
                system = platform.system()
                if system == "Windows":
                    subprocess.run(f'explorer "{current_dir}"', shell=True)
                elif system == "Darwin":  # macOS
                    subprocess.run(f'open "{current_dir}"', shell=True)
                else:  # Linux
                    subprocess.run(f'xdg-open "{current_dir}"', shell=True)
                    
                st.success(f"âœ… Opened directory: {current_dir}")
            except Exception as e:
                log_error(f"Failed to open directory: {e}")
                st.error("Could not open directory automatically")
    
    # Allow manual directory input
    new_dir = st.text_input(
        "Custom output directory path:",
        value=current_dir,
        help="Enter a custom directory path where professional WAV files will be saved"
    )
    
    if new_dir != current_dir:
        if st.button("âœ… Update Directory", key="update_dir"):
            try:
                Path(new_dir).mkdir(parents=True, exist_ok=True)
                st.session_state.output_directory = new_dir
                st.success(f"âœ… Updated output directory to: {new_dir}")
                log_verbose(f"Output directory changed to: {new_dir}")
                st.rerun()
            except Exception as e:
                log_error(f"Failed to create directory: {new_dir} - {e}")
                st.error(f"Failed to create directory: {e}")

def render_file_history() -> None:
    """Render the file history section"""
    if st.session_state.file_history:
        st.subheader("ðŸ“š Recent Files")
        
        # Show file history in a nice format
        for i, file_entry in enumerate(st.session_state.file_history[:5]):  # Show last 5 files
            file_col1, file_col2, file_col3 = st.columns([3, 1, 1])
            
            with file_col1:
                st.write(f"**{file_entry['filename']}**")
                st.caption(f"ðŸ“… {file_entry['timestamp']} | ðŸ“„ {file_entry['stats']['entries']} entries | ðŸ“ {file_entry['stats']['sentences']} sentences")
            
            with file_col2:
                if st.button(f"ðŸ“‚ Load", key=f"load_history_{i}"):
                    load_file_from_history(file_entry)
                    st.rerun()
            
            with file_col3:
                if i == 0:  # Only show for most recent file
                    st.caption("ðŸ†• Latest")
        
        # Clear history button
        if st.button("ðŸ—‘ï¸ Clear History", key="clear_file_history"):
            clear_file_history()
            st.rerun()
        
        st.markdown("---")

def render_timecode_analysis(subtitles: List[Dict[str, Any]]) -> Optional[List[Dict[str, Any]]]:
    """Render timecode analysis and conversion preview"""
    if not subtitles or not st.session_state.audio_calculator:
        return None
    
    st.header("ðŸŽ¬ Timecode Analysis")
    
    # Generate audio timing map
    audio_map = st.session_state.audio_calculator.generate_precise_audio_map(subtitles)
    
    if not audio_map:
        st.warning("No valid timing data found")
        return None
    
    # Display summary statistics
    col1, col2, col3, col4 = st.columns(4)
    
    optimal_count = sum(1 for seg in audio_map if seg['recommendation'] == 'OPTIMAL')
    too_long_count = sum(1 for seg in audio_map if seg['recommendation'] == 'TEXT_TOO_LONG')
    too_short_count = sum(1 for seg in audio_map if seg['recommendation'] == 'TEXT_TOO_SHORT')
        
    with col1:
        st.metric("âœ… Optimal Timing", optimal_count)
    with col2:
        st.metric("âŒ Text Too Long", too_long_count)
    with col3:
        st.metric("âš ï¸ Text Too Short", too_short_count)
    with col4:
        st.metric("ðŸŽ¬ Total Segments", len(audio_map))
    
    # Show timing analysis table
    st.subheader("ðŸ“Š Detailed Timing Analysis")
    
    # Create analysis dataframe for display
    analysis_data = []
    for segment in audio_map[:10]:  # Show first 10 for preview
        analysis_data.append({
            'Timecode Start': segment['start_timecode'],
            'Timecode End': segment['end_timecode'],
            'Duration (s)': f"{segment['duration_seconds']:.3f}",
            'Text Preview': segment['text'][:30] + "..." if len(segment['text']) > 30 else segment['text'],
            'Words': segment['word_count'],
            'Speed Factor': f"{segment['speed_factor']:.2f}x",
            'Status': segment['recommendation']
        })
    
    if analysis_data:
        try:
            import pandas as pd
            df = pd.DataFrame(analysis_data)
            st.dataframe(df, use_container_width=True)
        except ImportError:
            # Fallback if pandas not available
            for i, data in enumerate(analysis_data):
                st.write(f"**{i+1}.** {data['Timecode Start']} â†’ {data['Timecode End']} | {data['Status']}")
                st.caption(f"Text: {data['Text Preview']} | Duration: {data['Duration (s)']}s")
        
        if len(audio_map) > 10:
            st.info(f"Showing first 10 of {len(audio_map)} segments")
    
    # Export timing analysis
    if st.button("ðŸ“‹ Export Full Timing Analysis"):
        export_data = []
        for segment in audio_map:
            export_data.append({
                'Subtitle #': segment['subtitle_number'],
                'SRT Start': segment['original_srt_start'],
                'SRT End': segment['original_srt_end'],
                'Timecode Start': segment['start_timecode'],
                'Timecode End': segment['end_timecode'],
                'Duration (frames)': segment['duration_frames'],
                'Duration (seconds)': segment['duration_seconds'],
                'Text': segment['text'],
                'Word Count': segment['word_count'],
                'Character Count': segment['char_count'],
                'Natural Duration': segment['natural_duration'],
                'Speed Factor': segment['speed_factor'],
                'Recommendation': segment['recommendation']
            })
        
        try:
            import pandas as pd
            export_df = pd.DataFrame(export_data)
            csv = export_df.to_csv(index=False)
        except ImportError:
            # Fallback CSV generation
            csv = "Subtitle #,SRT Start,SRT End,Timecode Start,Timecode End,Duration (frames),Duration (seconds),Text,Word Count,Character Count,Natural Duration,Speed Factor,Recommendation\n"
            for data in export_data:
                csv += f"{data['Subtitle #']},{data['SRT Start']},{data['SRT End']},{data['Timecode Start']},{data['Timecode End']},{data['Duration (frames)']},{data['Duration (seconds)']},\"{data['Text']}\",{data['Word Count']},{data['Character Count']},{data['Natural Duration']},{data['Speed Factor']},{data['Recommendation']}\n"        
        st.download_button(
            label="ðŸ’¾ Download Timing Analysis (CSV)",
            data=csv,
            file_name=f"timecode_analysis_{st.session_state.frame_rate}fps_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    return audio_map

def render_voice_selection() -> Tuple[Optional[str], Optional[str]]:
    """Render voice selection interface"""
    if not st.session_state.voices:
        return None, None
        
    # Language selection with prominent Croatian and English options
    st.subheader("ðŸŒ Select Language & Voice")
    
    # Quick language selection
    lang_col1, lang_col2, lang_col3 = st.columns([1, 1, 2])
    
    with lang_col1:
        if st.button("ðŸ‡­ðŸ‡· Croatian Voices", key="croatian_btn"):
            st.session_state.selected_language = "croatian"
    
    with lang_col2:
        if st.button("ðŸ‡¬ðŸ‡§ British English", key="british_btn"):
            st.session_state.selected_language = "british"
    
    with lang_col3:
        show_all_languages = st.checkbox("Show All Languages", value=False)
    
    # Voice selection based on selected language
    voice_options = {}
    
    if st.session_state.selected_language == "croatian":
        available_voices = st.session_state.croatian_voices
        st.info("ðŸ‡­ðŸ‡· **Croatian Neural Voices** - Best quality for Croatian content")
    elif st.session_state.selected_language == "british":
        available_voices = st.session_state.british_english_voices
        st.info("ðŸ‡¬ðŸ‡§ **British English Neural Voices** - Premium quality UK English voices")
    elif show_all_languages:
        # Show dropdown for all languages
        all_languages = set()
        for voice in st.session_state.voices:
            locale = voice.get('Locale', '')
            if locale:
                lang_name = locale.split('-')[0].upper()
                all_languages.add(lang_name)
        
        if all_languages:
            selected_lang_code = st.selectbox(
                "Select Language",
                sorted(list(all_languages)),
                index=sorted(list(all_languages)).index("HR") if "HR" in all_languages else 0
            )
            
            available_voices = [v for v in st.session_state.voices 
                             if v.get('Locale', '').upper().startswith(selected_lang_code)]
        else:
            available_voices = []
    else:
        available_voices = st.session_state.croatian_voices
    
    # Create voice options
    if available_voices:
        for voice in available_voices:
            quality_indicator = "â­ Neural" if "Neural" in voice.get('VoiceTag', '') else "Standard"
            display_name = f"{voice['FriendlyName']} ({voice['Locale']}) - {voice.get('Gender', 'Unknown')} - {quality_indicator}"
            voice_options[display_name] = voice['Name']
        
        selected_voice_display = st.selectbox(
            "ðŸŽ¤ Select Voice",
            list(voice_options.keys()),
            index=0,
            help="Neural voices provide the highest quality output"
        )
        selected_voice = voice_options[selected_voice_display]
        return selected_voice, selected_voice_display
    else:
        st.warning("No voices available for the selected language.")
        return None, None

def render_sidebar_controls() -> Tuple[int, int, int, List[Any]]:
    """Render sidebar audio controls and options"""
    st.sidebar.subheader("ðŸŽ›ï¸ Voice Controls")
    speed = st.sidebar.slider("Speed", -50, 100, 0, 5, help="Adjust speech speed")
    volume = st.sidebar.slider("Volume", -50, 50, 0, 5, help="Adjust volume level")
    pitch = st.sidebar.slider("Pitch", -200, 200, 0, 10, help="Adjust voice pitch")
    
    # Professional BWF settings
    st.sidebar.subheader("ðŸŽ¬ BWF Professional Settings")
    st.sidebar.write("**Frame Rate:** " + st.session_state.frame_rate + " FPS")
    st.sidebar.write("**Format:** Broadcast Wave (BWF)")
    st.sidebar.write("**Sample Rate:** 48 kHz")
    st.sidebar.write("**Bit Depth:** 24-bit")
    st.sidebar.write("**Channels:** Stereo")
    st.sidebar.write("**Timecode:** Frame-accurate")
    
    # Transliteration status
    st.sidebar.subheader("ðŸ”¤ Transliteration")
    st.sidebar.write("**Cyrillic Detection:** Automatic")
    st.sidebar.write("**Voice Consistency:** Maintained")
    st.sidebar.write("**Transliteration:** Cyrillic â†’ Latin")
    st.sidebar.write("**No Voice Switching:** âœ…")
    
    # Professional features info
    st.sidebar.subheader("ðŸŽ¯ Professional Features")
    st.sidebar.write("âœ… BWF format with metadata")
    st.sidebar.write("âœ… Frame-accurate alignment")
    st.sidebar.write("âœ… Intelligent speed adjustment")
    st.sidebar.write("âœ… Professional timing reports")
    st.sidebar.write("âœ… Cyrillic transliteration")
    st.sidebar.write("âœ… Consistent voice throughout")
    
    return speed, volume, pitch, []  # Return empty list for compatibility

def render_voice_preview(selected_voice: str, speed: int, volume: int, pitch: int) -> None:
    """Render voice preview section"""
    st.header("ðŸŽ§ Voice Preview")
    preview_text = "Pozdrav! Ovo je pregled odabranog glasa s vaÅ¡im trenutnim postavkama." if st.session_state.selected_language == "croatian" else "Hello! This is a preview of the selected voice with your current settings."
    
    preview_text_input = st.text_area(
        "Test text for preview:",
        preview_text,
        height=100
    )
    
    if st.button("ðŸ”Š Preview Voice"):
        with st.spinner("Generating preview..."):
            try:
                # Simple preview generation using Edge TTS
                rate_str = f"{speed:+d}%" if speed != 0 else "+0%"
                volume_str = f"{volume:+d}%" if volume != 0 else "+0%"
                pitch_str = f"{pitch:+d}Hz" if pitch != 0 else "+0Hz"
                
                async def generate_preview():
                    communicate = edge_tts.Communicate(
                        preview_text_input,
                        selected_voice,
                        rate=rate_str,
                        volume=volume_str,
                        pitch=pitch_str
                    )
                    
                    audio_data = b""
                    async for chunk in communicate.stream():
                        if chunk["type"] == "audio":
                            audio_data += chunk["data"]
                    
                    return audio_data
                
                preview_audio = asyncio.run(generate_preview())
                
                if preview_audio:
                    st.audio(preview_audio, format='audio/mp3')
                    st.success("Preview ready!")
                else:
                    st.error("Failed to generate preview audio")
            except Exception as e:
                log_error(f"Preview generation failed: {e}")
                st.error("Failed to generate preview. Please try again.")

def render_professional_audio_generation(audio_map: List[Dict[str, Any]], selected_voice: str, 
                                       speed: int, volume: int, pitch: int) -> None:
    """Render professional audio generation with frame-accurate alignment"""
    if not audio_map or not st.session_state.precision_generator:
        return
    
    st.header("ðŸŽ¬ Professional BWF Audio Generation")
    
    # Generate filename with frame rate info
    output_dir = get_output_directory()
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"professional_bwf_{st.session_state.frame_rate}fps_{timestamp}.wav"
    output_filepath = os.path.join(output_dir, filename)
    
    # Display BWF information
    st.info(f"ðŸŽ¬ Frame Rate: {st.session_state.frame_rate} FPS | Format: Broadcast Wave (BWF)")
    st.info(f"ðŸ“Š 48 kHz / 24-bit Stereo | Cyrillic Transliteration: Enabled")
    st.info(f"ðŸ“ Output: {filename}")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ðŸŽ¬ Generate Professional BWF Audio", type="primary"):
            # Clear previous streaming status
            st.session_state.streaming_files = {}
            
            # Progress tracking
            progress_bar = st.progress(0)
            status_container = st.empty()
            timecode_container = st.empty()
            
            def update_progress(current_idx, current_text, start_time_ref, total_segments, start_timecode="", end_timecode=""):
                try:
                    progress = current_idx / total_segments if total_segments > 0 else 0
                    progress_bar.progress(progress)
                    
                    elapsed_time = time.time() - start_time_ref
                    if current_idx > 0:
                        avg_time_per_segment = elapsed_time / current_idx
                        eta_seconds = avg_time_per_segment * (total_segments - current_idx)
                        eta_text = format_time(eta_seconds)
                    else:
                        eta_text = "Calculating..."
                    
                    status_container.markdown(f"""
                    <div class="progress-details">
                        <strong>ðŸŽ¬ Professional BWF Generation:</strong> {current_idx}/{total_segments} segments ({progress:.1%})<br>
                        <strong>â±ï¸ Elapsed:</strong> {format_time(elapsed_time)}<br>
                        <strong>ðŸŽ¯ ETA:</strong> {eta_text}<br>
                        <strong>ðŸ“ BWF Output:</strong> <code>{os.path.basename(output_filepath)}</code><br>
                        <strong>ðŸ”¤ Transliteration:</strong> Active (maintains voice consistency)
                    </div>
                    """, unsafe_allow_html=True)
                    
                    if start_timecode and end_timecode:
                        text_preview = current_text[:80] + "..." if len(current_text) > 80 else current_text
                        timecode_container.markdown(f"""
                        <div class="current-sentence">
                            <strong>ðŸŽ¬ Processing BWF Timecode:</strong> {start_timecode} â†’ {end_timecode}<br>
                            <strong>ðŸ“ Text:</strong> "{text_preview}"<br>
                            <strong>ðŸŽ¤ Voice:</strong> Consistent throughout (no switching)
                        </div>
                        """, unsafe_allow_html=True)
                except Exception as e:
                    log_error(f"Error in professional progress callback: {e}")
            
            try:
                st.info("ðŸŽ¬ Starting professional BWF generation with frame-accurate timecode alignment...")
                
                # Generate professional BWF audio
                audio_data = asyncio.run(
                    st.session_state.precision_generator.generate_aligned_audio(
                        audio_map, selected_voice, speed, volume, pitch,
                        update_progress, output_filepath, st.session_state.voices
                    )
                )
                
                if audio_data and os.path.exists(output_filepath):
                    progress_bar.progress(1.0)
                    file_size = os.path.getsize(output_filepath)
                    
                    status_container.markdown(f"""
                    <div class="success-message">
                        <strong>âœ… Professional BWF Audio Complete!</strong><br>
                        <strong>ðŸ“ File:</strong> <code>{os.path.basename(output_filepath)}</code><br>
                        <strong>ðŸ“Š Size:</strong> {format_file_size(file_size)}<br>
                        <strong>ðŸŽ¬ Frame Rate:</strong> {st.session_state.frame_rate} FPS<br>
                        <strong>ðŸŽµ Format:</strong> Broadcast Wave (BWF) | 48 kHz | 24-bit | Stereo<br>
                        <strong>ðŸ”¤ Transliteration:</strong> Cyrillic â†’ Latin (consistent voice)<br>
                        <strong>ðŸ“ Location:</strong> <code>{output_filepath}</code>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    timecode_container.empty()
                    
                    # Add file operation buttons
                    btn_col1, btn_col2, btn_col3 = st.columns(3)
                    
                    with btn_col1:
                        if st.button("ðŸ“‚ Open BWF File Location"):
                            try:
                                file_dir = os.path.dirname(output_filepath)
                                system = platform.system()
                                if system == "Windows":
                                    subprocess.run(f'explorer /select,"{output_filepath}"', shell=True)
                                elif system == "Darwin":  # macOS
                                    subprocess.run(f'open -R "{output_filepath}"', shell=True)
                                else:  # Linux
                                    subprocess.run(f'xdg-open "{file_dir}"', shell=True)
                                st.success("âœ… BWF file location opened")
                            except Exception as e:
                                st.error(f"Could not open file location: {e}")
                    
                    with btn_col2:
                        # Provide BWF download
                        with open(output_filepath, 'rb') as f:
                            st.download_button(
                                label="ðŸ’¾ Download BWF File",
                                data=f.read(),
                                file_name=os.path.basename(output_filepath),
                                mime="audio/wav"
                            )
                    
                    with btn_col3:
                        # Show professional timing report if available
                        report_path = output_filepath.replace('.wav', '_professional_report.json')
                        if os.path.exists(report_path):
                            with open(report_path, 'r', encoding='utf-8') as f:
                                report_data = f.read()
                            st.download_button(
                                label="ðŸ“Š Download Professional Report",
                                data=report_data,
                                file_name=os.path.basename(report_path),
                                mime="application/json"
                            )
                    
                    # Display BWF technical info
                    st.markdown("---")
                    st.subheader("ðŸ“Š BWF Technical Information")
                    
                    tech_col1, tech_col2, tech_col3 = st.columns(3)
                    
                    with tech_col1:
                        st.write("**Format Specifications:**")
                        st.write("ðŸŽµ Broadcast Wave Format (BWF)")
                        st.write("ðŸ“Š 48 kHz Sample Rate")
                        st.write("ðŸ”Š 24-bit PCM")
                        st.write("ðŸŽ§ Stereo (2 channels)")
                    
                    with tech_col2:
                        st.write("**Timecode Information:**")
                        st.write(f"ðŸŽ¬ {st.session_state.frame_rate} FPS")
                        drop_frame = "Yes" if st.session_state.timecode_handler.drop_frame else "No"
                        st.write(f"â±ï¸ Drop Frame: {drop_frame}")
                        st.write(f"ðŸ“ Frame Duration: {st.session_state.timecode_handler.get_frame_duration_ms():.3f} ms")
                    
                    with tech_col3:
                        st.write("**Processing Features:**")
                        st.write("ðŸ”¤ Cyrillic Transliteration")
                        st.write("ðŸŽ¤ Consistent Voice")
                        st.write("âš¡ Intelligent Speed Adjustment")
                        st.write("ðŸ“Š Professional Metadata")
                
                else:
                    st.error("âŒ Failed to generate professional BWF audio. Please check the debug section for details.")
                    
            except Exception as e:
                log_error(f"Error during professional BWF audio generation: {e}")
                st.error(f"âŒ Professional BWF generation failed: {str(e)}")
                
                with st.expander("ðŸ” Technical Error Details"):
                    st.code(traceback.format_exc(), language="text")
    
    with col2:
        st.subheader("ðŸŽ¬ BWF Professional Features")
        st.write("âœ… Broadcast Wave Format (BWF)")
        st.write("âœ… Frame-accurate timecode metadata")
        st.write("âœ… 48 kHz / 24-bit professional audio")
        st.write("âœ… Intelligent speed adjustment")
        st.write("âœ… Cyrillic-to-Latin transliteration")
        st.write("âœ… Consistent voice (no switching)")
        st.write("âœ… Professional metadata embedding")
        st.write("âœ… Comprehensive timing reports")
        
        if audio_map:
            total_duration = audio_map[-1]['end_time_seconds'] if audio_map else 0
            cyrillic_count = sum(1 for seg in audio_map 
                              if CyrillicTransliterator().has_cyrillic(seg['text']))
            
            st.metric("ðŸŽ¬ Total Timeline", f"{total_duration:.3f}s")
            st.metric("ðŸŽ¯ Frame Rate", f"{st.session_state.frame_rate} FPS")
            st.metric("ðŸ”¤ Cyrillic Segments", f"{cyrillic_count}")
            
            if cyrillic_count > 0:
                st.info(f"ðŸ”¤ {cyrillic_count} segments will be transliterated to maintain voice consistency")

def render_debug_section() -> None:
    """Render debug and monitoring section"""
    st.markdown("---")
    st.subheader("ðŸ”§ Debug & Monitoring")
    
    debug_col1, debug_col2 = st.columns(2)
    
    with debug_col1:
        st.markdown("### ðŸ“Š Current Processing Phase")
        st.markdown(f"""
        <div class="phase-indicator">
            ðŸŽ¯ {st.session_state.current_phase}
        </div>
        """, unsafe_allow_html=True)
        
        # Professional tool status
        st.markdown("### ðŸŽ¬ Professional Tools Status")
        if st.session_state.timecode_handler:
            st.success(f"âœ… Timecode Handler: {st.session_state.frame_rate} FPS")
        else:
            st.error("âŒ Timecode Handler: Not initialized")
            
        if st.session_state.audio_calculator:
            st.success("âœ… Audio Calculator: Ready")
        else:
            st.error("âŒ Audio Calculator: Not initialized")
            
        if st.session_state.precision_generator:
            st.success("âœ… Precision Generator: Ready")
        else:
            st.error("âŒ Precision Generator: Not initialized")
        
        # Verbose log display
        if st.session_state.verbose_log:
            st.markdown("### ðŸ“ Verbose Processing Log")
            
            # Verbose log control buttons
            verbose_btn_col1, verbose_btn_col2 = st.columns(2)
            with verbose_btn_col1:
                if st.button("ðŸ“‹ Copy Verbose Log", key="copy_verbose"):
                    verbose_text = "\n".join(st.session_state.verbose_log)
                    st.code(verbose_text, language="text")
                    st.success("âœ… Verbose log displayed above - you can select and copy the text")
            
            with verbose_btn_col2:
                if st.button("ðŸ—‘ï¸ Clear Verbose Log", key="clear_verbose"):
                    st.session_state.verbose_log = []
                    st.rerun()
            
            # Display verbose log
            verbose_text = "\n".join(st.session_state.verbose_log[-20:])  # Show last 20 entries
            st.markdown(f"""
            <div class="verbose-log">
                {verbose_text}
            </div>
            """, unsafe_allow_html=True)
        else:
            st.info("ðŸ” No verbose logs yet. Logs will appear during audio generation.")
    
    with debug_col2:
        # Error log display
        if st.session_state.error_log:
            st.markdown("### âŒ Error Log")
            
            # Error log control buttons
            error_btn_col1, error_btn_col2 = st.columns(2)
            with error_btn_col1:
                if st.button("ðŸ“‹ Copy All Errors", key="copy_errors"):
                    all_errors = "\n\n" + "="*50 + "\n\n".join(st.session_state.error_log)
                    st.code(all_errors, language="text")
                    st.success("âœ… All errors displayed above - you can select and copy the text")
            
            with error_btn_col2:
                if st.button("ðŸ—‘ï¸ Clear All Errors", key="clear_errors"):
                    st.session_state.error_log = []
                    log_verbose("Error log cleared by user")
                    st.rerun()
            
            # Show error count and summary
            st.warning(f"âš ï¸ {len(st.session_state.error_log)} total errors detected")
            
            # Display individual errors
            for i, error in enumerate(reversed(st.session_state.error_log[-5:])):  # Show last 5 errors
                with st.expander(f"Error {len(st.session_state.error_log) - i}", expanded=(i == 0)):
                    st.markdown(f"""
                    <div class="error-details">
                        {error}
                    </div>
                    """, unsafe_allow_html=True)
        else:
            st.success("âœ… No errors detected")
        
        # System information
        st.markdown("### ðŸ’» System Information")
        st.write(f"**Python Version:** {sys.version}")
        st.write(f"**Application Version:** {VERSION}")
        st.write(f"**Build:** {BUILD}")
        st.write(f"**Output Directory:** {get_output_directory()}")
        if st.session_state.voices:
            st.write(f"**Available Voices:** {len(st.session_state.voices)}")
        if st.session_state.file_history:
            st.write(f"**File History:** {len(st.session_state.file_history)} files")
        
        # Professional settings summary
        st.write(f"**Frame Rate:** {st.session_state.frame_rate} FPS")
        if st.session_state.timecode_handler:
            st.write(f"**Drop Frame:** {'Yes' if st.session_state.timecode_handler.drop_frame else 'No'}")

# Simple TTS Tab Functions
def render_simple_tts_tab() -> None:
    """Render simple text-to-speech tab"""
    st.header("ðŸŽ¤ Simple Text-to-Speech")
    st.info("Convert any text directly to audio without timecode constraints")
    
    # Text input area
    text_input = st.text_area(
        "Enter your text to convert to speech:",
        value=getattr(st.session_state, 'simple_tts_text', ''),
        placeholder="Type or paste your text here...",
        height=200,
        help="Enter any text you want to convert to audio. No subtitle timing required.",
        key="simple_text_input"
    )
    
    if text_input.strip():
        # Show text statistics
        word_count = len(text_input.split())
        char_count = len(text_input)
        estimated_duration = (word_count / 150) * 60  # Assuming 150 WPM
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Words", word_count)
        with col2:
            st.metric("Characters", char_count)
        with col3:
            st.metric("Est. Duration", f"{estimated_duration:.1f}s")
        
        # Load voices if not already loaded
        if not st.session_state.voices_loaded:
            load_voices_async()
        
        # Voice selection for simple TTS
        if st.session_state.voices:
            st.subheader("ðŸŽ¤ Voice Selection")
            selected_voice, _ = render_voice_selection()
            
            if selected_voice:
                # Audio controls in columns
                control_col1, control_col2 = st.columns(2)
                
                with control_col1:
                    st.subheader("ðŸŽ›ï¸ Audio Settings")
                    speed = st.slider("Speech Speed", -50, 100, 0, 5, help="Adjust speech speed", key="simple_speed")
                    volume = st.slider("Volume Level", -50, 50, 0, 5, help="Adjust volume level", key="simple_volume")
                    pitch = st.slider("Voice Pitch", -200, 200, 0, 10, help="Adjust voice pitch", key="simple_pitch")
                
                with control_col2:
                    st.subheader("ðŸ”¤ Text Processing")
                    
                    # Check if text contains Cyrillic
                    transliterator = CyrillicTransliterator()
                    has_cyrillic = transliterator.has_cyrillic(text_input)
                    
                    if has_cyrillic:
                        st.warning("ðŸ”¤ Cyrillic text detected")
                        use_transliteration = st.checkbox(
                            "Enable Cyrillic transliteration", 
                            value=True,
                            help="Convert Cyrillic characters to Latin for better voice consistency"
                        )
                        
                        if use_transliteration:
                            processed_text = transliterator.transliterate(text_input)
                            st.info("Preview of transliterated text:")
                            preview_text = processed_text[:200] + "..." if len(processed_text) > 200 else processed_text
                            st.text(preview_text)
                        else:
                            processed_text = text_input
                    else:
                        processed_text = text_input
                        st.success("âœ… Text ready for speech synthesis")
                
                # Generation buttons
                st.markdown("---")
                gen_col1, gen_col2 = st.columns(2)
                
                with gen_col1:
                    if st.button("ðŸ”Š Preview Audio", key="simple_preview", type="secondary"):
                        generate_simple_preview(processed_text, selected_voice, speed, volume, pitch)
                
                with gen_col2:
                    if st.button("ðŸŽµ Generate Full Audio File", key="simple_generate", type="primary"):
                        generate_simple_audio_file(processed_text, selected_voice, speed, volume, pitch, word_count, char_count)
        else:
            st.warning("âš ï¸ No voices available. Please check your internet connection.")
            if st.button("ðŸ”„ Reload Voices", key="simple_reload_voices"):
                st.session_state.voices = []
                st.session_state.voices_loaded = False
                st.rerun()
    else:
        render_example_texts()

def load_voices_async() -> None:
    """Load voices asynchronously with caching"""
    if not st.session_state.voices and not st.session_state.voices_loaded:
        with st.spinner("ðŸ”„ Loading available voices..."):
            try:
                st.session_state.voices = asyncio.run(get_available_voices())
                # Categorize voices
                croatian, british_english, others = categorize_voices(st.session_state.voices)
                st.session_state.croatian_voices = croatian
                st.session_state.british_english_voices = british_english
                st.session_state.other_voices = others
                st.session_state.voices_loaded = True
                log_verbose(f"Loaded {len(st.session_state.voices)} voices")
            except Exception as e:
                log_error(f"Failed to load voices: {e}")
                st.error(f"Failed to load voices: {e}")

def generate_simple_preview(processed_text: str, selected_voice: str, speed: int, volume: int, pitch: int) -> None:
    """Generate and play audio preview"""
    with st.spinner("Generating preview..."):
        try:
            # Generate preview (limit to first 100 words for quick preview)
            preview_text_words = processed_text.split()[:100]
            preview_text_short = " ".join(preview_text_words)
            
            rate_str = f"{speed:+d}%" if speed != 0 else "+0%"
            volume_str = f"{volume:+d}%" if volume != 0 else "+0%"
            pitch_str = f"{pitch:+d}Hz" if pitch != 0 else "+0Hz"
            
            async def generate_preview_audio():
                communicate = edge_tts.Communicate(
                    preview_text_short,
                    selected_voice,
                    rate=rate_str,
                    volume=volume_str,
                    pitch=pitch_str
                )
                
                audio_data = b""
                async for chunk in communicate.stream():
                    if chunk["type"] == "audio":
                        audio_data += chunk["data"]
                
                return audio_data
            
            preview_audio = asyncio.run(generate_preview_audio())
            
            if preview_audio:
                st.audio(preview_audio, format='audio/mp3')
                st.success("âœ… Preview ready!")
                if len(preview_text_words) < len(processed_text.split()):
                    st.info(f"Preview shows first 100 words. Full text has {len(processed_text.split())} words.")
            else:
                st.error("Failed to generate preview")
                
        except Exception as e:
            log_error(f"Simple TTS preview failed: {e}")
            st.error(f"Preview failed: {e}")

def generate_simple_audio_file(processed_text: str, selected_voice: str, speed: int, volume: int, pitch: int, word_count: int, char_count: int) -> None:
    """Generate full audio file"""
    with st.spinner("Generating full audio file..."):
        try:
            # Generate filename
            output_dir = get_output_directory()
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"simple_tts_{timestamp}.wav"
            output_filepath = os.path.join(output_dir, filename)
            
            # Progress tracking
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            rate_str = f"{speed:+d}%" if speed != 0 else "+0%"
            volume_str = f"{volume:+d}%" if volume != 0 else "+0%"
            pitch_str = f"{pitch:+d}Hz" if pitch != 0 else "+0Hz"
            
            status_text.text("ðŸŽ¤ Initializing speech synthesis...")
            progress_bar.progress(0.2)
            
            async def generate_audio():
                communicate = edge_tts.Communicate(
                    processed_text,
                    selected_voice,
                    rate=rate_str,
                    volume=volume_str,
                    pitch=pitch_str
                )
                
                audio_data = b""
                chunk_count = 0
                async for chunk in communicate.stream():
                    if chunk["type"] == "audio":
                        audio_data += chunk["data"]
                        chunk_count += 1
                        # Update progress based on chunks received
                        progress = min(0.9, 0.2 + (chunk_count * 0.01))
                        progress_bar.progress(progress)
                
                return audio_data
            
            status_text.text("ðŸŽµ Generating audio...")
            audio_data = asyncio.run(generate_audio())
            progress_bar.progress(0.9)
            
            if audio_data:
                status_text.text("ðŸ’¾ Saving audio file...")
                
                # Save as professional WAV file
                temp_mp3_path = output_filepath.replace('.wav', '.tmp.mp3')
                
                # Save temporary MP3
                with open(temp_mp3_path, 'wb') as temp_file:
                    temp_file.write(audio_data)
                
                # Convert to professional WAV format
                try:
                    cmd = [
                        'ffmpeg', '-i', temp_mp3_path,
                        '-acodec', 'pcm_s24le',  # 24-bit PCM
                        '-ar', '48000',          # 48kHz
                        '-ac', '2',              # Stereo
                        '-metadata', f'title=Simple TTS - {timestamp}',
                        '-metadata', f'artist=Professional Dubbing Tool v{VERSION}',
                        '-metadata', f'comment=Generated from text input',
                        '-metadata', f'generator=Professional_Dubbing_Tool_v{VERSION}',
                        output_filepath, '-y'
                    ]
                    
                    subprocess.run(cmd, check=True, capture_output=True)
                    st.success("âœ… Professional WAV format")
                    
                except (subprocess.CalledProcessError, FileNotFoundError):
                    # Fallback: save as standard WAV
                    with open(output_filepath, 'wb') as wav_file:
                        wav_file.write(audio_data)
                    st.warning("âš ï¸ Saved as standard WAV (ffmpeg not available)")
                
                # Clean up temp file
                if os.path.exists(temp_mp3_path):
                    os.unlink(temp_mp3_path)
                
                progress_bar.progress(1.0)
                file_size = os.path.getsize(output_filepath)
                
                # Success message
                status_text.markdown(f"""
                <div class="success-message">
                    <strong>âœ… Audio file generated successfully!</strong><br>
                    <strong>ðŸ“ File:</strong> <code>{filename}</code><br>
                    <strong>ðŸ“Š Size:</strong> {format_file_size(file_size)}<br>
                    <strong>ðŸŽµ Format:</strong> Professional WAV | 48 kHz | 24-bit | Stereo<br>
                    <strong>ðŸ“ Words:</strong> {word_count} | <strong>ðŸ”¤ Characters:</strong> {char_count}<br>
                    <strong>ðŸ“ Location:</strong> <code>{output_filepath}</code>
                </div>
                """, unsafe_allow_html=True)
                
                # File operation buttons
                file_col1, file_col2, file_col3 = st.columns(3)
                
                with file_col1:
                    # Download button
                    with open(output_filepath, 'rb') as f:
                        st.download_button(
                            label="ðŸ’¾ Download Audio File",
                            data=f.read(),
                            file_name=filename,
                            mime="audio/wav"
                        )
                
                with file_col2:
                    # Play audio
                    with open(output_filepath, 'rb') as f:
                        st.audio(f.read(), format='audio/wav')
                
                with file_col3:
                    # Open file location
                    if st.button("ðŸ“‚ Open File Location", key="simple_open_location"):
                        try:
                            file_dir = os.path.dirname(output_filepath)
                            system = platform.system()
                            if system == "Windows":
                                subprocess.run(f'explorer /select,"{output_filepath}"', shell=True)
                            elif system == "Darwin":  # macOS
                                subprocess.run(f'open -R "{output_filepath}"', shell=True)
                            else:  # Linux
                                subprocess.run(f'xdg-open "{file_dir}"', shell=True)
                            st.success("âœ… File location opened")
                        except Exception as e:
                            st.error(f"Could not open file location: {e}")
                
                log_verbose(f"Simple TTS file generated: {filename} ({format_file_size(file_size)})")
                
            else:
                st.error("âŒ Failed to generate audio")
                
        except Exception as e:
            log_error(f"Simple TTS generation failed: {e}")
            st.error(f"âŒ Audio generation failed: {str(e)}")
            
            with st.expander("ðŸ” Error Details"):
                st.code(traceback.format_exc(), language="text")

def render_example_texts() -> None:
    """Render example text options"""
    st.info("ðŸ‘† Enter some text above to get started with simple text-to-speech conversion")
    
    # Show example texts
    st.subheader("ðŸ’¡ Example Texts")
    example_col1, example_col2 = st.columns(2)
    
    with example_col1:
        if st.button("ðŸ“ Load English Example", key="load_english_example"):
            example_text = """Hello and welcome to our professional audio dubbing tool. This is a simple text-to-speech conversion feature that allows you to convert any text directly into high-quality audio without needing to create subtitle timings first. You can use this for voiceovers, announcements, or quick audio previews."""
            st.session_state.simple_tts_text = example_text
            st.rerun()
    
    with example_col2:
        if st.button("ðŸ“ Load Croatian Example", key="load_croatian_example"):
            example_text = """Pozdrav i dobrodoÅ¡li u naÅ¡ profesionalni alat za sinkronizaciju zvuka. Ovo je jednostavna funkcija pretvaranja teksta u govor koja vam omoguÄ‡uje izravno pretvaranje bilo kojeg teksta u visokokvalitetni zvuk bez potrebe za prethodnim stvaranjem vremenskih oznaka podnaslova. MoÅ¾ete koristiti ovo za naracije, najave ili brze zvuÄne preglede."""
            st.session_state.simple_tts_text = example_text
            st.rerun()
    
    # Load example text if selected
    if hasattr(st.session_state, 'simple_tts_text') and st.session_state.simple_tts_text:
        st.text_area("Example text loaded:", st.session_state.simple_tts_text, height=100, disabled=True)

def render_professional_dubbing_tab() -> None:
    """Render the professional dubbing tab content"""
    # Professional settings
    render_professional_settings()
    
    # Output directory selector
    render_output_directory_selector()
    
    # Create main columns for file upload and voice settings
    col1, col2 = st.columns([3, 2])
    
    with col1:
        st.header("ðŸ“ Upload Subtitle File")
        
        # File History Section
        render_file_history()
        
        # Initialize content variables
        current_content = None
        current_sentences = []
        current_subtitles = []
        current_stats = None
        clean_text = ""
        audio_map = None
        
        # Check if we should auto-load the last file
        if st.session_state.auto_loaded_content:
            file_entry = st.session_state.auto_loaded_content
            
            st.success(f"ðŸ“‚ Auto-loaded from history: **{file_entry['filename']}**")
            current_content = file_entry['content']
            clean_text, current_sentences, current_subtitles = parse_srt_content(current_content)
            current_stats = file_entry['stats']
            
            # Show option to upload a different file
            if st.button("ðŸ“¤ Upload Different File", key="upload_different"):
                st.session_state.auto_loaded_content = None
                st.rerun()
        
        # File uploader (only show if no auto-loaded content)
        elif not st.session_state.auto_loaded_content:
            uploaded_file = st.file_uploader(
                "Choose an SRT file",
                type=['srt'],
                help="Upload your subtitle file (.srt format)"
            )
            
            if uploaded_file is not None:
                try:
                    # Read and parse SRT content
                    current_content = uploaded_file.read().decode('utf-8')
                    clean_text, current_sentences, current_subtitles = parse_srt_content(current_content)
                    current_stats = get_subtitle_stats(current_content, current_sentences, current_subtitles)
                    
                    # Add to history
                    add_to_file_history(uploaded_file.name, current_content, current_stats)
                    log_verbose(f"New file uploaded: {uploaded_file.name}")
                except Exception as e:
                    log_error(f"Failed to process uploaded file: {e}")
                    st.error("Failed to process the uploaded file. Please check the file format.")
        
        # Auto-load suggestion if no file is loaded but history exists
        if not current_content and st.session_state.file_history:
            st.info("ðŸ’¡ You have files in your history. Click below to load the most recent one:")
            if st.button("ðŸ“‚ Load Last File", key="load_last_suggestion"):
                load_file_from_history(st.session_state.file_history[0])
                st.rerun()
        
        # Process the current content (either uploaded or auto-loaded)
        if current_content and current_subtitles:
            if not clean_text:
                clean_text = '. '.join([s.get('text', '') for s in current_sentences]) + '.'
            
            # Display statistics
            st.markdown("""
            <div class="stats-container">
                <h3>ðŸ“Š Subtitle Statistics</h3>
            </div>
            """, unsafe_allow_html=True)
            
            stat_col1, stat_col2, stat_col3, stat_col4, stat_col5 = st.columns(5)
            with stat_col1:
                st.metric("Subtitle Entries", current_stats['entries'])
            with stat_col2:
                st.metric("Sentences", current_stats['sentences'])
            with stat_col3:
                st.metric("Total Characters", current_stats['characters'])
            with stat_col4:
                st.metric("Clean Text Words", current_stats['clean_words'])
            with stat_col5:
                st.metric("ðŸŽ¬ Frame Rate", f"{st.session_state.frame_rate} FPS")
            
            # Display preview of clean text
            st.subheader("ðŸ“ Extracted Text Preview")
            preview_text = clean_text[:500] + "..." if len(clean_text) > 500 else clean_text
            st.text_area("Text to be converted to professional audio:", preview_text, height=100, disabled=True)
            
            # Professional timecode analysis
            if st.session_state.audio_calculator:
                audio_map = render_timecode_analysis(current_subtitles)
            
            # Load voices if not already loaded
            if not st.session_state.voices_loaded:
                load_voices_async()
            
            if st.session_state.voices and audio_map:
                # Voice selection
                selected_voice, selected_voice_display = render_voice_selection()
                
                if selected_voice:
                    # Sidebar controls
                    speed, volume, pitch, _ = render_sidebar_controls()  # Ignore old options
                    
                    # Voice preview in right column
                    with col2:
                        render_voice_preview(selected_voice, speed, volume, pitch)
                    
                    # Professional audio generation
                    render_professional_audio_generation(audio_map, selected_voice, speed, volume, pitch)
            
            else:
                if not st.session_state.voices:
                    st.error("âŒ No voices could be loaded. Please check your internet connection and try again.")
                    st.info("ðŸ’¡ Make sure you have the required dependencies installed: `pip install edge-tts streamlit`")
                elif not audio_map:
                    st.info("ðŸ“ Timecode analysis failed. Please check your SRT file format.")
        
        elif current_content and not current_subtitles:
            st.warning("âš ï¸ No valid subtitles found in the uploaded SRT file. Please check the file format.")

# Additional utility functions for enhanced functionality
def validate_srt_format(content: str) -> bool:
    """Validate if the content is in proper SRT format"""
    try:
        # Basic SRT validation
        blocks = re.split(r'\n\s*\n', content.strip())
        for block in blocks:
            lines = block.strip().split('\n')
            if len(lines) < 3:
                continue
            
            # Check subtitle number
            try:
                int(lines[0].strip())
            except ValueError:
                return False
            
            # Check timing format
            timing_pattern = r'\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}'
            if not re.match(timing_pattern, lines[1].strip()):
                return False
        
        return True
    except Exception:
        return False

def get_system_info() -> Dict[str, str]:
    """Get comprehensive system information"""
    return {
        "platform": platform.system(),
        "platform_version": platform.version(),
        "python_version": sys.version,
        "streamlit_version": st.__version__ if hasattr(st, '__version__') else "Unknown",
        "app_version": VERSION,
        "build": BUILD,
        "timestamp": datetime.now().isoformat()
    }

def export_session_data() -> Dict[str, Any]:
    """Export current session data for backup/recovery"""
    try:
        return {
            "file_history": st.session_state.get('file_history', []),
            "frame_rate": st.session_state.get('frame_rate', DEFAULT_FRAME_RATE),
            "selected_language": st.session_state.get('selected_language', 'croatian'),
            "output_directory": st.session_state.get('output_directory', ''),
            "voices_loaded": st.session_state.get('voices_loaded', False),
            "export_timestamp": datetime.now().isoformat(),
            "system_info": get_system_info()
        }
    except Exception as e:
        log_error(f"Failed to export session data: {e}")
        return {}

def import_session_data(session_data: Dict[str, Any]) -> bool:
    """Import session data from backup"""
    try:
        if not session_data:
            return False
        
        # Restore session state safely
        for key, value in session_data.items():
            if key in ['file_history', 'frame_rate', 'selected_language', 'output_directory']:
                st.session_state[key] = value
        
        log_verbose("Session data imported successfully")
        return True
    except Exception as e:
        log_error(f"Failed to import session data: {e}")
        return False

def cleanup_temp_files() -> None:
    """Clean up temporary files created during processing"""
    try:
        output_dir = get_output_directory()
        temp_pattern = os.path.join(output_dir, "*.tmp.*")
        
        import glob
        temp_files = glob.glob(temp_pattern)
        
        for temp_file in temp_files:
            try:
                # Only delete files older than 1 hour
                if os.path.getmtime(temp_file) < time.time() - 3600:
                    os.unlink(temp_file)
                    log_verbose(f"Cleaned up temp file: {temp_file}")
            except OSError:
                continue
                
    except Exception as e:
        log_error(f"Error during temp file cleanup: {e}")

# Main Application Function
def main() -> None:
    """Main application function with professional dubbing features"""
    try:
        # Initialize application
        setup_page_config()
        apply_custom_css()
        initialize_session_state()
        initialize_professional_tools()
        
        # Header
        st.markdown(f"""
        <div class="main-header">
            <h1>ðŸŽ¬ Professional Audio Dubbing Tool</h1>
            <p>Frame-accurate audio generation with professional timecode alignment</p>
            <p><strong>Version {VERSION}</strong> | Build {BUILD}</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Create tabs for different modes
        tab1, tab2 = st.tabs(["ðŸŽ¬ Professional Dubbing", "ðŸŽ¤ Simple Text-to-Speech"])
        
        with tab1:
            # Professional dubbing tab (original functionality)
            render_professional_dubbing_tab()
        
        with tab2:
            # Simple text-to-speech tab (new functionality)
            render_simple_tts_tab()
        
        # Debug and monitoring section (shared across tabs)
        render_debug_section()
        
        # Footer with version information
        st.markdown(f"""
        <div class="version-footer">
            <p>ðŸŽ¬ <strong>Professional Audio Dubbing Tool v{VERSION}</strong> | Build {BUILD}</p>
            <p>Frame-accurate timecode alignment | Professional 48kHz/24-bit WAV output</p>
            <p>Supports multiple frame rates: 23.976, 24, 25, 29.97, 30, 50, 59.94, 60 FPS</p>
            <p>Built with Streamlit & Edge TTS | <strong>Professional Dubbing Technology</strong></p>
            <p><small>Croatian ðŸ‡­ðŸ‡· and British English ðŸ‡¬ðŸ‡§ with premium Neural voices | Cyrillic auto-detection</small></p>
        </div>
        """, unsafe_allow_html=True)
        
    except Exception as e:
        log_error(f"Critical error in main application: {e}")
        st.error("A critical error occurred. Please check the debug section for details.")
        
        # Emergency debug info
        st.subheader("ðŸš¨ Emergency Debug Information")
        st.code(f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}", language="text")

# Startup checks
def startup_checks() -> None:
    """Perform startup checks and initialization"""
    try:
        # Log startup
        log_verbose(f"Professional Audio Dubbing Tool v{VERSION} starting up...")
        
        # Clean up old temp files on startup
        cleanup_temp_files()
        
        log_verbose("Startup checks completed successfully")
        
    except Exception as e:
        log_error(f"Startup checks failed: {e}")

# Call startup checks when the module loads
startup_checks()

# Run the application
if __name__ == "__main__":
    main()